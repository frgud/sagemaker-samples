{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09932273-f544-4d94-80e8-2516aa9039e1",
   "metadata": {},
   "source": [
    "# Simple SageMaker Sample: XGBoost Hyperparameter Tuning, Training & Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a141c-be9e-4862-ac73-82672436553c",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Preparation](#Preparation)\n",
    "3. [Get the Data](#Download-and-prepare-the-data)\n",
    "4. [Simple Model Training](#Perform-a-simple-training-job)\n",
    "5. [Hyperparameter Optimization Model Training](#Hyper-parameter-tuning)\n",
    "6. [Deploy Model](#Deploy-our-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484f378-6f7c-44f0-955b-28f10698ba54",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook walks through building a SageMaker model using the SageMaker Python APIs.  We are using Tensorflow as the framework that drives our training jobs.  The samples here have been copied and modified from the various examples and notebooks published by AWS on the AWS GitHub site.\n",
    "\n",
    "NEED TO INCLUDE SOME PRIMITIVE DIAGRAMS AND IMAGES THAT DEFINE WHAT'S HAPPENING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b529ae4c-b9ea-4520-a3f3-4ed52cef015a",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1528cf48-5549-4343-983c-8dc05865b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.tuner import (\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_client = boto3.Session().client(\"sagemaker\")\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = \"sagemaker/DEMO-hpo-xgboost-dm\"\n",
    "\n",
    "# Request the algorithm image & version from this region...\n",
    "container = retrieve(\"xgboost\", region, \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6262f-7ba8-463c-bf21-8916f0c926da",
   "metadata": {},
   "source": [
    "## Download and Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d6caa-f384-4c61-aa2d-dc86d9d9b19f",
   "metadata": {},
   "source": [
    "## Perform a Simple Training Job\n",
    "\n",
    "In this section we'll discuss the various methods of training models in SageMaker.  We are using XGBoost as the avatar for this discussion.  There are several ways to train models in SageMaker; refer to the following outline for guidance.\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html#xgboost-modes\n",
    "1. Framework Mode vs. Script Mode\n",
    "2. Train XGBoost in Framework Mode\n",
    "3. Train XGBoost in Script Mode\n",
    "4. Train XGBoost as your own container\n",
    "5. Additional Considerations for Training XGBoost\n",
    "    a. [Training with Spot Instances](https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_managed_spot_training.html)\n",
    "    b. Distributed Training\n",
    "    c. [SageMaker Debugger](https://sagemaker-examples.readthedocs.io/en/latest/aws_sagemaker_studio/sagemaker_studio_image_build/xgboost_bring_your_own/Batch_Transform_BYO_XGB.html)\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html#xgboost-modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8c35359-34cd-48e1-b208-199df8c17d65",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bucket' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-91fb9233cf85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0minstance_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ml.m5.2xlarge\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"s3://{}/{}/{}/output\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"abalone-xgb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mcontent_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"libsvm\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bucket' is not defined"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_managed_spot_training.html\n",
    "# https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-python-sdk/tensorflow_moving_from_framework_mode_to_script_mode/tensorflow_moving_from_framework_mode_to_script_mode.html\n",
    "# USE THIS FOR the TRAINING ONLY SECTION\n",
    "# There's a conversation around training in framework vs. script mode.\n",
    "# Additionally there's a conversation around migrating from framework to script mode.\n",
    "# Spot Training is nuanced as well since requires checkpointing.\n",
    "# Finally let's address distributed training for framework mode.\n",
    "\n",
    "# If possible let's stick to framework mode entirely.\n",
    "# https://sagemaker.readthedocs.io/en/stable/frameworks/xgboost/using_xgboost.html#host-multiple-models-with-multi-model-endpoints\n",
    "\n",
    "hyperparameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"num_round\": \"50\",\n",
    "    \"verbosity\": \"2\",\n",
    "}\n",
    "\n",
    "instance_type = \"ml.m5.2xlarge\"\n",
    "output_path = \"s3://{}/{}/{}/output\".format(bucket, prefix, \"abalone-xgb\")\n",
    "content_type = \"libsvm\"\n",
    "\n",
    "import time\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "job_name = \"DEMO-xgboost-spot-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "use_spot_instances = True\n",
    "max_run = 3600\n",
    "max_wait = 7200 if use_spot_instances else None\n",
    "checkpoint_s3_uri = (\n",
    "    \"s3://{}/{}/checkpoints/{}\".format(bucket, prefix, job_name) if use_spot_instances else None\n",
    ")\n",
    "print(\"Checkpoint path:\", checkpoint_s3_uri)\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    volume_size=5,  # 5 GB\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    use_spot_instances=use_spot_instances,\n",
    "    max_run=max_run,\n",
    "    max_wait=max_wait,\n",
    "    checkpoint_s3_uri=checkpoint_s3_uri,\n",
    ")\n",
    "train_input = TrainingInput(\n",
    "    s3_data=\"s3://{}/{}/{}\".format(bucket, prefix, \"train\"), content_type=\"libsvm\"\n",
    ")\n",
    "estimator.fit({\"train\": train_input}, job_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042dc35c-bb21-4ba7-be53-eb148e7e5213",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d11eaa9a-24fb-4fa5-a69d-27f7a86390eb",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning\n",
    "\n",
    "Hyperparameter Tuning is a feature of Amazon SageMaker that allows customers to find the best hyperparameter values for their training jobs in the least amount of time.  This feature is available in the SageMaker UI within the AWS Console, the AWS CLI, and via the Python SageMaker API.  We will describe how to submit a HTJ (Hyperparameter Tuning Job) via API calls in this document.\n",
    "\n",
    "The steps to submit an HTJ via the SageMaker Python API are as follows:\n",
    "1. Decide which algorithm you want to tune.\n",
    "2. Set initial weights on the hyperparameters for the selected algorithm.\n",
    "3. Define the range of hyperparameters you want to tune against.\n",
    "4. Define your hyperparameter tuning job.\n",
    "5. Train your hyperparameter tuning job.\n",
    "6. Evaluate the your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd10fc6-f89b-4558-8f7b-953be4715889",
   "metadata": {},
   "source": [
    "### Decide which algorithm to tune\n",
    "Amazon SageMaker Hyperparameter Tuning allows you to tune built-in SageMaker algorithms as well as custom algorithms that you bring to the training environment.  To complete this process, you need to pull the model container using the `sagemaker.image_uris.retrieve` function call.  This function takes a model name, region and version number as parameters and returns a container object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe7dc4d-f1a5-4e8b-8d29-5b2053d017d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_url\n",
    "from sagemaker.image_urls import retrieve\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Create a reference to an XGBoost model with the retrieved image\n",
    "# The API call tells SageMaker what the algorithm is, what permissions it has, \n",
    "#   what kind and how many instances to train with, where output should do,\n",
    "#   and the session credentials for this algorithms.\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc80ced-0e17-4a67-b18b-2e1be17107e1",
   "metadata": {},
   "source": [
    "### Set Initial Weights on Hyperparameters\n",
    "\n",
    "Every algorithms has different hyperparameters.  Before you run a training job for hyperparameter tuning you need to set default weights on the algorithm for these hyperparameters.  During this phase we will also set the objective metric for the HTJ.\n",
    "\n",
    "The objective metric is a metric used by Amazon SageMaker to compare the performance of hyperparameter tuning jobs against each other.  The model with the best performing metric is the model that should be used for training.\n",
    "\n",
    "Every algorithm will have different hyperparameters.  It is important to understand what these hyperparameters are and they work at a high level before running an HTJ.  [XGBoost Hyperparameters & Objective Metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html) are listed in the AWS Documentation for Amazon SageMaker.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6af5e7-6daa-47e5-a777-1e91b37da83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the initial weights on XGBoost\n",
    "xgb.set_hyperparameters(\n",
    "    eval_metric=\"auc\",\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=10,\n",
    "    rate_drop=0.3,\n",
    "    tweedie_variance_power=1.4,\n",
    ")\n",
    "\n",
    "# Set the Objective Metric to compare job runs.\n",
    "# This validation metric is Area Under the Curve.\n",
    "objective_metric_name = \"validation:auc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a3d2d1-9338-4085-9dbc-fc35d0393816",
   "metadata": {},
   "source": [
    "### Define the range of Hyperparameters you want to Tune\n",
    "\n",
    "Amazon SageMaker Hyperparameter Tuning Jobs require a specific range of values to use when testing hyperparameters.  You need to specify these ranges as `sagemaker.parameter.ParameterRange` objects in a dictionary.  This class is implemented in the `sagemaker.tuner` package with implementations for `IntegerParameter`, `CategoricalParameter` & `ContinuousParameter`.  In this example, we'll tune continuous parameters.\n",
    "\n",
    "When specifying a parameter to tune, you pass a minimum value, a maximum value, and a scaling type.  Amazon SageMaker Hyperparameter Tuning Jobs support Linear and Logarithmic scaling for parameters.  Test both and see which perform best for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc7bc75-1241-4c72-9bfc-b0396d7bd66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import ContinuousParameter\n",
    "\n",
    "hyperparameter_ranges_logarithmic = {\n",
    "    \"alpha\": ContinuousParameter(0.01, 10, scaling_type=\"Logarithmic\"),\n",
    "    \"labmda\": ContinuousParameter(0.01, 10, scaling_type=\"Logarithmic\"),\n",
    "}\n",
    "\n",
    "hyperparameter_ranges_linear = {\n",
    "    \"alpha\": ContinuousParameter(0.01, 10, scaling_type=\"Linear\"),\n",
    "    \"labmda\": ContinuousParameter(0.01, 10, scaling_type=\"Linear\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946fb5d-f1bc-4bb9-be1d-15b3552fb4c3",
   "metadata": {},
   "source": [
    "### Define the Hyperparameter Tuning Job\n",
    "\n",
    "A Hyperparameter Tuning Job is represented in the SageMaker API as a `HyperparameterTuner` object.  To create this object we must pass in many of the objects we've created up until this point.  We supply the algorithm we will tune, the objective metric, and the hyperparameter ranges.  Furthermore, we will set the number of jobs to run and the parallelization of these jobs.  \n",
    "\n",
    "Finally, we must specify our tuning strategy.  Hyperparameter Tuning Jobs take a `Random` or `Bayesian` strategy, and we will showcase both in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb232d9-ef7a-4a3a-b43e-2c65e9f5262c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-84654d8cb8aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m random_linear_tuner_log = HyperparameterTuner(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mobjective_metric_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mhyperparameter_ranges_linear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "# Random Search Hyperparameter Tuning Job that scales Linearly.\n",
    "random_linear_tuner_log = HyperparameterTuner(\n",
    "    xgb,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges_linear,\n",
    "    max_jobs=5, max_parallel_jobs=5,\n",
    "    strategy=\"Random\",\n",
    ")\n",
    "\n",
    "# Random Search Hyperparameter Tuning Job that scales Logarithmically.\n",
    "random_logarithmic_tuner_log = HyperparameterTuner(\n",
    "    xgb,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges_logarithmic,\n",
    "    max_jobs=5, max_parallel_jobs=5,\n",
    "    strategy=\"Random\",\n",
    ")\n",
    "\n",
    "# Bayesian Search Hyperparameter Tuning Job that scales Linearly.\n",
    "bayesian_linear_tuner_log = HyperparameterTuner(\n",
    "    xgb,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges_linear,\n",
    "    max_jobs=5, max_parallel_jobs=5,\n",
    "    strategy=\"Bayesian\",\n",
    ")\n",
    "\n",
    "# Bayesian Search Hyperparameter Tuning Job that scales Logarithmically.\n",
    "bayesian_logarithmic_tuner_log = HyperparameterTuner(\n",
    "    xgb,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges_logarithmic,\n",
    "    max_jobs=5, max_parallel_jobs=5,\n",
    "    strategy=\"Bayesian\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50d387-3d76-435f-a801-26a2d9bd81a7",
   "metadata": {},
   "source": [
    "### Submit the Hyperparameter Tuning Job\n",
    "\n",
    "The `fit(dict, bool)` method submits your Hyperparameter Tuning Job to Amazon SageMaker.  The hardware specified in the algorithm definition is initialized and the jobs are run in accordance with the instructions defined within the `HyperparameterTuner` job.\n",
    "\n",
    "The hyperparameter ranges we've specified will be tested and modified across all of the jobs that run; these values will change based on the scaling strategy you utilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43d298d-773b-4aa0-aec8-b86ebb51a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_linear_tuner_log.fit(\n",
    "    {\"train\": s3_input_train, \"validation\": s3_input_validation},\n",
    "    include_cls_metadata=False,\n",
    "    job_name=\"random_linear_tuner\"\n",
    ")\n",
    "\n",
    "random_logarithmic_tuner_log(\n",
    "    {\"train\": s3_input_train, \"validation\": s3_input_validation},\n",
    "    include_cls_metadata=False,\n",
    "    job_name=\"random_logarithmic_tuner\"\n",
    ")\n",
    "\n",
    "bayesian_linear_tuner_log(\n",
    "    {\"train\": s3_input_train, \"validation\": s3_input_validation},\n",
    "    include_cls_metadata=False,\n",
    "    job_name=\"bayesian_linear_tuner\"\n",
    ")\n",
    "\n",
    "bayesian_logarithmic_tuner_log(\n",
    "    {\"train\": s3_input_train, \"validation\": s3_input_validation},\n",
    "    include_cls_metadata=False,\n",
    "    job_name=\"bayesian_logarithmic_tuner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f936691-d75e-4ca7-b735-7e60f7af1ead",
   "metadata": {},
   "source": [
    "### Evaluate the results\n",
    "\n",
    "In this section we will use the Hyperparameter Tuning Job API to retrieve performance statistics for the 4 jobs we have built in this demo.  We start by checking if the jobs have completed.  Once completed, we get dataframes plotting the results of the Hyperparameter Tuning Jobs.  We supplement these jobs with meta data about the job run and then create a pandas dataframe.  Using third party libraries we plot these values out in a visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b8158d0-7743-4039-ad54-2c61bcd22108",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boto3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bb50314f3fe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sagemaker\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Check if the jobs have completed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'boto3' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "client = boto3.client(\"sagemaker\")\n",
    "\n",
    "####################################\n",
    "# Check if the jobs have completed #\n",
    "####################################\n",
    "\n",
    "random_linear_status_log = client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=random_linear_tuner_log.latest_tuning_job.job_name\n",
    ")[\"HyperParameterTuningJobStatus\"]\n",
    "\n",
    "random_logarithmic_status_log = client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=random_logarithmic_tuner_log.latest_tuning_job.job_name\n",
    ")[\"HyperParameterTuningJobStatus\"]\n",
    "\n",
    "bayesian_linear_status_log = client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=bayesian_linear_tuner_log.latest_tuning_job.job_name\n",
    ")[\"HyperParameterTuningJobStatus\"]\n",
    "\n",
    "bayesian_logarithmic_status_log = client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=bayesian_logarithmic_tuner_log.latest_tuning_job.job_name\n",
    ")[\"HyperParameterTuningJobStatus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "737a5af8-a2c4-44a0-a391-b109f78546e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sagemaker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fc7b76d1ba42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m random_linear_df_log = sagemaker.HyperparameterTuningJobAnalytics(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mrandom_linear_status_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_tuning_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ).dataframe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sagemaker' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "########################################################################\n",
    "# Gather the HyperparameterTuningJobAnalytics for each of jobs we ran. #\n",
    "########################################################################\n",
    "\n",
    "random_linear_df_log = sagemaker.HyperparameterTuningJobAnalytics(\n",
    "    random_linear_status_log.latest_tuning_job.job_name\n",
    ").dataframe()\n",
    "random_linear_df_log[\"strategy\"] = \"random\"\n",
    "random_linear_df_log[\"scaling\"] = \"linear\"\n",
    "\n",
    "random_logarithmic_df_log = sagemaker.HyperparameterTuningJobAnalytics(\n",
    "    random_logarithmic_df_log.latest_tuning_job.job_name\n",
    ").dataframe()\n",
    "random_logarithmic_df_log[\"strategy\"] = \"random\"\n",
    "random_logarithmic_df_log[\"scaling\"] = \"logarithmic\"\n",
    "\n",
    "bayesian_linear_df_log = sagemaker.HyperparameterTuningJobAnalytics(\n",
    "    bayesian_linear_status_log.latest_tuning_job.job_name\n",
    ").dataframe()\n",
    "bayesian_linear_df_log[\"strategy\"] = \"bayesian\"\n",
    "bayesian_linear_df_log[\"scaling\"] = \"linear\"\n",
    "\n",
    "bayesian_logarithmic_df_log = sagemaker.HyperparameterTuningJobAnalytics(\n",
    "    bayesian_logarithmic_status_log.latest_tuning_job.job_name\n",
    ").dataframe()\n",
    "bayesian_logarithmic_df_log[\"strategy\"] = \"bayesian\"\n",
    "bayesian_logarithmic_df_log[\"scaling\"] = \"logarithmic\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94087d02-2bc1-46cb-9019-3272973561e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_linear_df_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-82fcbb29f9fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m df = pd.concat([\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mrandom_linear_df_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mrandom_logarithmic_df_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbayesian_linear_df_log\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_linear_df_log' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "########################################################################\n",
    "# Create the Pandas dataframe that plots the performance of our models #\n",
    "########################################################################\n",
    "\n",
    "df = pd.concat([\n",
    "    random_linear_df_log,\n",
    "    random_logarithmic_df_log,\n",
    "    bayesian_linear_df_log,\n",
    "    bayesian_logarithmic_df_log\n",
    "], ignore_index=True)\n",
    "\n",
    "g = sns.FacetGrid(df, col=\"scaling\", palette=\"viridis\")\n",
    "g = g.map(plt.scatter, \"alpha\", \"lambda\", alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660a0ab5-039c-4881-a410-2c57036d30be",
   "metadata": {},
   "source": [
    "This concludes our segment on Hyperparameter Tuning.  The next task is to select the model we want to work with and deploy that model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01079a2a-8916-4f7d-a2d2-bc17b981151d",
   "metadata": {},
   "source": [
    "## Deploy Our Model\n",
    "In this section we will discuss two seperate deployment paradigms.  We will deploy our model using a SageMaker hosted endpoint first, followed by a local deployment.  The steps for local deployment can be reused to deploy to a machine in a private or self-hosted environment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
